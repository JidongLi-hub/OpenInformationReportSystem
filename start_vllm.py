import subprocess
import os
import sys

# --- é…ç½®åŒºåŸŸ ---
MODEL_PATH = "Qwen/Qwen2-7B-Instruct"
SERVED_NAME = "Qwen/Qwen2-7B-Instruct"
# ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨å†·é—¨é«˜ä½ç«¯å£ï¼Œé¿å…å†²çª
PORT = 28888 
MAX_MEMORY_USAGE = 1000

def get_free_gpus():
    """æŸ¥è¯¢ç©ºé—²æ˜¾å¡"""
    try:
        result = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=index,memory.used", "--format=csv,noheader,nounits"],
            encoding="utf-8"
        )
        free_gpus = []
        for line in result.strip().split('\n'):
            index, memory = line.split(',')
            if int(memory.strip()) < MAX_MEMORY_USAGE:
                free_gpus.append(index.strip())
        return free_gpus
    except Exception as e:
        print(f"âŒ è·å–æ˜¾å¡çŠ¶æ€å¤±è´¥: {e}")
        sys.exit(1)

def main():
    print("ğŸ” æ­£åœ¨æ‰«ææœåŠ¡å™¨æ˜¾å¡çŠ¶æ€...")
    free_gpus = get_free_gpus()
    
    if not free_gpus:
        print("âŒ é”™è¯¯: å½“å‰æ²¡æœ‰ç©ºé—²çš„æ˜¾å¡ï¼")
        sys.exit(1)
    
    print(f"âœ… å‘ç°ç©ºé—²æ˜¾å¡: {free_gpus}")
    
    # ç­–ç•¥: ä¼˜å…ˆå‡‘ 2 å¼ å¡
    if len(free_gpus) >= 2:
        target_gpus = free_gpus[:2]
        tp_size = 2
        print(f"ğŸš€ ç­–ç•¥: ä½¿ç”¨ GPU {target_gpus} (åŒå¡å¹¶è¡Œ)")
    else:
        target_gpus = free_gpus[:1]
        tp_size = 1
        print(f"âš ï¸ ç­–ç•¥: ä½¿ç”¨ GPU {target_gpus} (å•å¡æ¨¡å¼)")

    gpu_str = ",".join(target_gpus)
    
    # --- ç¯å¢ƒå˜é‡è®¾ç½® ---
    env = os.environ.copy()
    env["CUDA_VISIBLE_DEVICES"] = gpu_str
    
    # 1. æ¸…ç†ä»£ç†
    proxies = ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY", "all_proxy", "ALL_PROXY"]
    for p in proxies:
        if p in env: del env[p]
    
    # 2. å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
    env["HF_HUB_OFFLINE"] = "1"

    cmd = [
        "python", "-m", "vllm.entrypoints.openai.api_server",
        "--model", MODEL_PATH,
        "--served-model-name", SERVED_NAME,
        "--trust-remote-code",
        "--tensor-parallel-size", str(tp_size),
        "--port", str(PORT)
    ]
    
    print("-" * 50)
    print(f"ğŸš€ å‡†å¤‡åœ¨ç«¯å£ {PORT} å¯åŠ¨æ¨¡å‹...")
    print(f"æ‰§è¡Œå‘½ä»¤: CUDA_VISIBLE_DEVICES={gpu_str} ... --port {PORT}")
    print("-" * 50)
    
    try:
        subprocess.run(cmd, env=env, check=True)
    except KeyboardInterrupt:
        print("\nğŸ›‘ æœåŠ¡å·²åœæ­¢ã€‚")
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ æœåŠ¡å¯åŠ¨å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
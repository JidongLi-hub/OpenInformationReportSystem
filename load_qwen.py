from vllm import LLM

print("ã€ç¬¬1æ­¥ã€‘å¼€å§‹åŠ è½½ Qwen2-7B-Instruct æ¨¡å‹...")
print("ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œä¼šä»ç½‘ç»œä¸‹è½½æ¨¡å‹ï¼Œå¤§çº¦ 15GBï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰")

# åŠ è½½æ¨¡å‹
# å…³é”®ä¿®æ”¹ï¼šé™åˆ¶æ˜¾å­˜ä½¿ç”¨ç‡
llm = LLM(
    model="Qwen/Qwen2-7B-Instruct",
    gpu_memory_utilization=0.8,   # ğŸ‘ˆ é™åˆ¶ä¸º 80% æ˜¾å­˜ï¼ˆçº¦ 64GBï¼‰ï¼Œç•™å‡º 16GB å®‰å…¨ä½™é‡
    dtype="auto"                  # è‡ªåŠ¨é€‰æ‹© float16
)

print("ã€ç¬¬2æ­¥ã€‘æ¨¡å‹åŠ è½½æˆåŠŸï¼ğŸ‰")
print("ç°åœ¨å¯ä»¥ç”Ÿæˆæ–‡æœ¬äº†ï¼Œæˆ‘ä»¬è¯•ä¸€å¥ä¸­æ–‡...")

# æµ‹è¯•ç”Ÿæˆ
outputs = llm.generate(["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"], use_tqdm=False)
print("ã€ç¬¬3æ­¥ã€‘æ¨¡å‹å›å¤ï¼š")
print(outputs[0].outputs[0].text)
